README (tier 1 documentation)


Code documentation (1-2 pages per tier)
Note that this should not simply be a re-printing of the code with the comments in bold (or something similar).
In general:
¥	Provide a description of the function of subroutines and programs. It should describe WHAT the functions do not HOW they do it (such comments should appear in the code).
¥	Provide an explanation of the structure of the code - i.e. what calls what - describing (perhaps as a diagram) how separate pieces of code or subroutines (and HTML for the front end) interact with one another.
¥	Explain how to install and run the software. For example, how are the programs run to populate the database? Are there other programs that must be run to calculate and store the information on chromosome codon usage before these are stored in the database? If so, how are these run?
For specific layers, the documentation should:
¥	Front-end provide a short end-user document, and explain what middle layer code was accessed and how the results were displayed in CGI scripts. You should document any semantic markup used.
¥	Business logic define the API provided to the front end in such a way that another programmer could implement a front end with reference to your document.
¥	Data access routines (which may be provided by the database programmer or the business logic programmer) define the API provided to the business logic in such a way that another programmer could implement the business logic with reference to your document.
¥	Database provide table definitions and UML diagrams (or equivalent) detailing indexes, primary and foreign keys, and any constraints.



GenBank file parser and database connection
===========================================
Files: parser.py, split_file.py

Description of project
----------------------
This tier of the project aims to parse a GenBank file and store some
relevant information in an SQL database.

Setup
-----
Some steps must be taken prior to use of the parser.
Please see the 'Dependencies' section below for required imports.
As well as these, before using the parser.py file, the split_file.py
script must be run with a GenBank format file.
This takes the raw GenBank file and splits it at the '//' entry separator.
Thus, a separate file for each gene locus is generated.
Ensure that these files are contained in a directory with nothing
else in it.
Once this step has been completed, set the 'indir' variable in the
parser.py script to the directory containing your split files.

Dependencies
------------
split_file.py:
    import re

parser.py:
    import re
    import os
    import pandas as pd
    import mysql.connector
    from sqlalchemy import create_engine

Data extraction tier
--------------------

Functions
#########

First core function: numerical_split
Parameters:
1. filename
It then converts the string filename into an integer.
This allows the match_finder function to iterate
through the filenames in the correct numerical order.

Second core function: match_finder
Parameters:
1. list - this is an empty list in which you want to store the
   function output
2. compiler - this is the regex compiler in the format:
              compiler = re.compile(r" regex here ", re.MULTILINE|re.DOTALL)
3. else_statement - this is the value that will be appended to the
   list specified in parameter 1. if no value can be found by the
   regex in the GenBank file.
   DEFAULT = 'None'

Third core function: findall_matcher
Parameters:
1. list_ - this is an empty list in which you want to store the
   function output
2. pattern - this is the findall regex pattern in the form r"pattern"

The match_finder and findall_matcher functions search in each
file in the indir directory for the pattern specified.
The difference being that the match_finder function is useful when
you require just one occurence of the defined pattern but the findall_matcher
captures all of the occurences of the defined pattern in the file

Implementation
##############

Here, the functions are used to extract useful parts of the GenBank file.
Regular expressions have been designed to extract key data the match_finder
function stores into the following lists:

****************************************************************************************
List name           |   Description                                                   |
****************************************************************************************
gene_ids            |   unique locus identifier                                       |
genbank_accessions  |   unique genbank identifier                                     |
gene_name           |   name of the gene                                              |
dna_seq             |   nucleotide sequence of the gene                               |
gene_products       |   this list contains the 1st protein product of the gene        |
chr_loc             |   chromosomal location of the locus                             |
protein_seq         |   amino acid sequence encoded by the coding sequence of the gene|
exon_start          |   contains sub-lists of exon start positions for each locus     |
exon_end            |   contains sub-lists of exon end positions for each locus       |
****************************************************************************************

Data processing
###############

Some of the data requires additional post-population processing
dna_seq:
        cleaning of whitespaces and digits present in the GenBank file
protein_seq:
        cleaning of whitespaces
cds_grab:
        cds_grab is the inital list containing the raw strings
        It then undergoes the following:
        - Stripping of whitespaces, use of sublist in the for loop
          as some loci have >1 /CDS (coding sequence entry).
          The list then becomes the new list: cds_ws_strip.
        - Extra characters are then stripped with re.sub() functions,
          resulting in the list clean_boundaries.
        - Then the items (now in the form '123..456') are split into
          individual items. A separate sublist for each locus is maintained.
        - After this, exons that span multiple genes are removed.
          These can be identified by the fact that accession numbers referencing
          other loci are embedded in the /CDS entry. For these loci, the phrase
          'exons span multiple genes' are appended to the list.
        - The list is now called remove_spans
        - Two more for loops then search for the first and last number
          in the '123..456' format items using regexes
        - These are stored in lists called exon_start and exon_end

Preparing the data for database import
######################################
The tables of the database are fed the following data:-

    Table 1
    Coding_region:
       - gene_ids as 'Gene_ID'
       - exon start as 'Start_location'
       - exon end as 'End_location'
    Table 2
    Gene_info
       - gene_ids as 'Gene_ID'
       - chr_loc as 'Chromosome_location'
       - clean_dna_seq as DNA_sequence
       - clean_protein_seq as Protein_sequence
       - gene_products as Protein_product

Preparing exon_start and exon_end:
A zip object called zipped_id_start_end is created - it is a
list of tuples.
A list comprehension is utilised to go from lists of
lists (exon_start, exon_end) to a list of tuples with repeating
gene_ids i.e. any one gene_ids entry will be contained in n rows where
n is the number of start positions and corresponding end positions.
The code then searches for splice variants.
An enumerating for loop identifies the gene_ids associated with
these, and removes any splice variant tuples from the
zipped_id_start_end list.

Preparing the data for table 1:
Using pandas (imported as pd), the zip object is converted to a DataFrame.
Preparing the data for table 2:
Using pandas (imported as pd), the five lists named under 'Table 2' are
converted to a dataframe object.

A connection to the database is generated using the sqlAlchemy function
create_engine.
mysql.connector is then used to port the dataframes into the database.






